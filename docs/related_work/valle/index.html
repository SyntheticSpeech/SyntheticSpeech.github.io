<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="VALL-E # VALL-E is a neural codec language model for text-to-speech (TTS) synthesis that can generate high-quality speech that is indistinguishable from human speech. It is trained on a massive dataset of text and audio, and can also clone speakers&rsquo; voices, even from a short sample of their speech. VALL-E works by first converting text into a sequence of discrete codes. These codes are then used to generate a corresponding sequence of audio tokens.">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="VALL-E" />
<meta property="og:description" content="VALL-E # VALL-E is a neural codec language model for text-to-speech (TTS) synthesis that can generate high-quality speech that is indistinguishable from human speech. It is trained on a massive dataset of text and audio, and can also clone speakers&rsquo; voices, even from a short sample of their speech. VALL-E works by first converting text into a sequence of discrete codes. These codes are then used to generate a corresponding sequence of audio tokens." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://syntheticspeech.github.io/docs/related_work/valle/" /><meta property="article:section" content="docs" />



<title>VALL-E | Synthetic Audio Generation</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" >
<link rel="stylesheet" href="/book.min.33a48f5432973b8ff9a82679d9e45d67f2c15d4399bd2829269455cfe390b5e8.css" integrity="sha256-M6SPVDKXO4/5qCZ52eRdZ/LBXUOZvSgpJpRVz&#43;OQteg=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.45fad7fa511be8bb2cf71e3728177e3486dc4e1490e6653f4f39b1270cd094d6.js" integrity="sha256-RfrX&#43;lEb6Lss9x43KBd&#43;NIbcThSQ5mU/TzmxJwzQlNY=" crossorigin="anonymous"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>Synthetic Audio Generation</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/deepfakes-history/" class="">Deepfakes, Then and Now</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/our-research/" class="">Our Research</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9af0df7d567019df4426974c16eb7aff" class="toggle"  />
    <label for="section-9af0df7d567019df4426974c16eb7aff" class="flex justify-between">
      <a role="button" class="">Samples</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/samples/xtts_vallex/" class="">XTTS vs. VALL-E-X</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-696a5458982dba1505ce49c97f207fbd" class="toggle" checked />
    <label for="section-696a5458982dba1505ce49c97f207fbd" class="flex justify-between">
      <a href="/docs/related_work/" class="">Related Work</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/related_work/zero-shot-tts/" class="">Zero-Shot TTS</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/related_work/valle/" class="active">VALL-E</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/references/" class="">References</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/team/" class="">Meet the Team</a>
  

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>VALL-E</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#key-features">Key features</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="vall-e">
  VALL-E
  <a class="anchor" href="#vall-e">#</a>
</h1>
<p><a href="https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e/">VALL-E</a> is a neural codec language model for text-to-speech (TTS) synthesis that can generate high-quality speech that is indistinguishable from human speech. It is trained on a massive dataset of text and audio, and can also clone speakers&rsquo; voices, even from a short sample of their speech.
VALL-E works by first converting text into a sequence of discrete codes. These codes are then used to generate a corresponding sequence of audio tokens. The audio tokens are then decoded into a waveform using a neural audio codec model.</p>
<p><img src="../../assets/images/valle.png" alt="valle" /></p>
<h3 id="key-features">
  Key features
  <a class="anchor" href="#key-features">#</a>
</h3>
<ul>
<li>Uses a language modeling approach and applies it to TTS.</li>
<li>Train a neural codec language model using discrete codes derived from an off-the-shelf neural audio codec model, and regard TTS as a conditional language modeling task rather than continuous signal regression.</li>
<li>The model takes in text prompts as phonemes and a 3-second recording sample from the target speaker.</li>
<li>The model then generates the corresponding acoustic tokens conditioned on the acoustic tokens of the 3-second recording and the phoneme prompt.</li>
<li>Finally, the generated acoustic tokens are used to synthesize the final waveform with corresponding neural codec decoder.</li>
</ul>
<p>Ultimately, VALL-E generates synthetic, natural-sounding speech with high degree of similarity to the speaker with zero-shot prompting, outperforming YourTTS on LibriSpeech and VCTK.</p>
<h1 id="vall-e-x">
  VALL-E X
  <a class="anchor" href="#vall-e-x">#</a>
</h1>
<p><a href="https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-x/">VALL-E X</a> is an extension of VALL-E that enables cross-lingual text-to-speech synthesis and speech-to-speech translation. It is trained on a multilingual dataset of text and audio, and can synthesize speech in a target language from a text prompt in the source language, while preserving the speaker&rsquo;s voice, emotion, and acoustic environment.YourTTSYourTTS is a zero-shot multi-speaker text-to-speech (TTS) model that can generate realistic and engaging speech for a wide range of applications, even without having to train it on a large amount of data. It achieves this by using a number of modifications to the VITS TTS model, including external speaker embeddings, a multilingual training dataset, and joint training of the speaker encoder and decoder.</p>
<p><img src="../../assets/images/vallex.png" alt="vallex" /></p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#key-features">Key features</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












