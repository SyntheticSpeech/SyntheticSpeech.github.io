<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Synthetic Audio Generation</title>
    <link>https://syntheticspeech.github.io/docs/samples/</link>
    <description>Recent content on Synthetic Audio Generation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Nov 2023 14:54:44 -0700</lastBuildDate>
    <atom:link href="https://syntheticspeech.github.io/docs/samples/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>XTTS vs. VALL-E-X</title>
      <link>https://syntheticspeech.github.io/docs/samples/xtts_vallex/</link>
      <pubDate>Wed, 01 Nov 2023 14:54:44 -0700</pubDate>
      <guid>https://syntheticspeech.github.io/docs/samples/xtts_vallex/</guid>
      <description>XTTS vs. VALL-E-X # We present the results of our work below, categorized based on the models we ran and the different vocal features we were testing for.
Custom Voice Input # Input voice: XTTS VALL-E-X Voice with Emotion # These samples demonstrate how XTTS and VALL-E X retain the emotion of the input voice.
Input voice (Emotion: Amused): XTTS VALL-E-X Input voice (Emotion: Anger): XTTS VALL-E-X Input voice (Emotion: Disgust): XTTS VALL-E-X Voice with Environmental Noise and Textures # These samples demonstrate how XTTS and VALL-E X handle voice inputs that have an environment or texture that causes the voice to sound like it has a filter.</description>
    </item>
    <item>
      <title>Fine-tuned VALL-E X</title>
      <link>https://syntheticspeech.github.io/docs/samples/fine-tune-vallex/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/samples/fine-tune-vallex/</guid>
      <description> Fine-tuned VALL-E X # Input sample Output sample </description>
    </item>
    <item>
      <title>Fine-tuned yourTTS</title>
      <link>https://syntheticspeech.github.io/docs/samples/fine-tune-yourtts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/samples/fine-tune-yourtts/</guid>
      <description> Fine-tuned yourTTS # Unfortunately, we were not obtain good results with this model at all. We have just provided an output for documentation purposes: </description>
    </item>
    <item>
      <title>Fine-tuned VITS</title>
      <link>https://syntheticspeech.github.io/docs/samples/fine_tune_vits/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/samples/fine_tune_vits/</guid>
      <description> Fine-tuned VITS # Using Anne Hathaway&amp;rsquo;s Voice as Input # Input sample Output
Condition Sample Output 1 using a prompt from the input sample Output 2 using a prompt from the input sample Output 3 using a prompt from the input sample Using a long sentence as the text prompt Using an input sample from the training dataset Custom Input Voice # Input sample Output sample Long Input Voice (Chinese) # Input sample Output sample LibriSpeech Input # Input sample Output sample </description>
    </item>
  </channel>
</rss>
