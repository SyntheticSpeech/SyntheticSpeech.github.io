<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on Synthetic Audio Generation</title>
    <link>https://syntheticspeech.github.io/docs/</link>
    <description>Recent content in Docs on Synthetic Audio Generation</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Nov 2023 14:54:44 -0700</lastBuildDate>
    <atom:link href="https://syntheticspeech.github.io/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deepfakes, Then and Now</title>
      <link>https://syntheticspeech.github.io/docs/deepfakes-history/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/deepfakes-history/</guid>
      <description>Deepfakes, Then and Now # Deepfake videos and images that convincingly replace one person&amp;rsquo;s likeness with another&amp;rsquo;s, have rapidly grown in popularity and sophistication. The generation of deepfakes for both benign and nefarious purposes has only become more accessible through apps like FakeApp, Synthesia, Deepfakesweb.com and more. As a result, research into deepfakes has surged, driven by the need to understand, detect, and mitigate the potential threats they pose.</description>
    </item>
    <item>
      <title>Our Research</title>
      <link>https://syntheticspeech.github.io/docs/our-research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/our-research/</guid>
      <description>Our Research # VITS # VITS is a previous SOTA model. It is the first end-to-end model compare to previous 2-stage model, meaning there is no need to produce intermediate mel-spectrums.
Our fine-tuning code is based on this repo.
The repo has a pretrained model on VCTK and some Animes. It can be used for fine-tuning Chinese, Japanese and English.
We self recorded a tiny collection of voices, and tried to fine-tune pretrained VITS model based on this dataset.</description>
    </item>
    <item>
      <title>Meet the Team</title>
      <link>https://syntheticspeech.github.io/docs/team/</link>
      <pubDate>Wed, 01 Nov 2023 14:54:44 -0700</pubDate>
      <guid>https://syntheticspeech.github.io/docs/team/</guid>
      <description> Meet the Team # *Draft* # TODO: Images, contact and info
As part of a collboration between SLAC, CMU and Stanford.
Sponsor
Mayank Malik (SLAC) Engineering Team
Hao (CMU) Nivea (CMU) Sivani (CMU) Thenuga (CMU) Tianyi (CMU) Special Thanks to CMU Faculty
David Varodayan Cynthia Kuo Sujata Telang Gladys Mercier </description>
    </item>
    <item>
      <title>Samples</title>
      <link>https://syntheticspeech.github.io/docs/samples/</link>
      <pubDate>Wed, 01 Nov 2023 14:54:44 -0700</pubDate>
      <guid>https://syntheticspeech.github.io/docs/samples/</guid>
      <description> Samples # XTTS and VALL-E-X # Speaker Prompt VALL-E X XTTS hao_31_24000.mp4 hao_vallex.mp4 hao_xtts.mp4 amused.mp4 vallex-amused.mp4 xtts-amused.mp4 anger.mp4 vallex-anger.mp4 xtts-anger.mp4 disgust.mp4 vallex-amused.mp4 xtts-amused.mp4 muffled.mp4 vallex-muffled.mp4 xtts-muffled.mp4 libri.mp4 libri-vallex.mp4 libri-xtts.mp4 vctk.mp4 vctk-vallex.mp4 vctk-xtts.mp4 </description>
    </item>
    <item>
      <title>References</title>
      <link>https://syntheticspeech.github.io/docs/references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://syntheticspeech.github.io/docs/references/</guid>
      <description>References # *Draft* # TODO: Formatting to apa/mla
https://arxiv.org/pdf/2210.13438.pdf — The Encodec paper (High Fidelity Neural Audio Compression) https://wiki.aalto.fi/display/ITSP/Concatenative+speech+synthesis — Explanation on concatenative speech synthesis https://www.youtube.com/watch?v=aLBedWj-5CQ&amp;t=1s — Deep dive into speech synthesis meetup (HuggingFace) https://www.youtube.com/watch?v=MA8PCvmr8B0 — Pushing the frontier of neural text to speech (Microsoft Research) https://www.youtube.com/watch?v=G9k-2mYl6Vo&amp;t=5593s — Excellent video by John Tan Chong Min about VALL-E https://www.youtube.com/watch?v=mV7bhf6b2Hs — Excellent video by Aleksa Gordic about Encodec</description>
    </item>
  </channel>
</rss>
